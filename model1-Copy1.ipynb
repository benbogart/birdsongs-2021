{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kapre in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (0.3.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from kapre) (1.19.5)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from kapre) (2.4.1)\n",
      "Requirement already satisfied: librosa>=0.7.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from kapre) (0.8.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (0.53.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (0.24.1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (0.10.3.post1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (1.0.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (2.1.9)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from librosa>=0.7.2->kapre) (1.6.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.7.2->kapre) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.7.2->kapre) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (20.9)\n",
      "Requirement already satisfied: requests in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (2.25.1)\n",
      "Requirement already satisfied: appdirs in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from resampy>=0.2.2->librosa>=0.7.2->kapre) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.7.2->kapre) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from soundfile>=0.9.0->librosa>=0.7.2->kapre) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa>=0.7.2->kapre) (2.20)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (2.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (2.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (3.15.6)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (1.12)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (2.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (1.32.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (0.3.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorflow>=2.0.0->kapre) (3.7.4.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->kapre) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->kapre) (1.28.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->kapre) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->kapre) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->kapre) (0.4.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->kapre) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->kapre) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->kapre) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->kapre) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->kapre) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre) (1.26.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->kapre) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/benbogart/opt/anaconda3/envs/audio-ml/lib/python3.8/site-packages (from packaging->pooch>=1.0->librosa>=0.7.2->kapre) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# the model requires kapre\n",
    "!pip install kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "def _construct_milsed_block(num_blocks, dropout_rate = False):\n",
    "\n",
    "    sample_rate = 22050\n",
    "    input_shape = (sample_rate * 10, 1) # mono 10 seconds at 22050hz\n",
    "    'n_mels'\n",
    "    n_fft = 2048 # frame size\n",
    "    hop_length = 256\n",
    "    n_mels=256\n",
    "    mel_f_min=0.0\n",
    "    mel_f_max=None\n",
    "    return_decibel=True\n",
    "    model = K.Sequential()\n",
    "    composed_melgram_layer = \\\n",
    "        kapre.composed.get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                                sample_rate=sample_rate,\n",
    "                                                n_fft=n_fft,\n",
    "                                                n_mels=n_mels,\n",
    "                                                mel_f_min=mel_f_min,\n",
    "                                                mel_f_max=mel_f_max,\n",
    "                                                return_decibel=return_decibel)\n",
    "\n",
    "    # decompose the layers the model can be saved\n",
    "    for layer in composed_melgram_layer.layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "\n",
    "    # add blocks\n",
    "    n_filters = 16\n",
    "    for block in range(num_blocks):\n",
    "        model.add(K.layers.Convolution2D(n_filters, (3, 3),\n",
    "                                       padding='same',\n",
    "                                       activation='relu',\n",
    "                                       kernel_initializer='he_normal'))\n",
    "        model.add(K.layers.BatchNormalization())\n",
    "        model.add(K.layers.Convolution2D(n_filters, (3, 3),\n",
    "                                       padding='same',\n",
    "                                       activation='relu',\n",
    "                                       kernel_initializer='he_normal'))\n",
    "        model.add(K.layers.BatchNormalization())\n",
    "        model.add(K.layers.MaxPooling2D((2,2), padding='valid'))\n",
    "\n",
    "        # double the number of filters for the next block\n",
    "        n_filters *= 2\n",
    "\n",
    "    model.add(K.layers.GlobalMaxPooling2D())\n",
    "\n",
    "    model.add(K.layers.Dense(1028, activation='relu'))\n",
    "    if dropout_rate:\n",
    "        model.add(K.layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(K.layers.Dense(512, activation='relu'))\n",
    "    if dropout_rate:\n",
    "        model.add(K.layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(K.layers.Dense(264, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _construct_milsed_block(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained weights\n",
    "#model.load_weights('/kaggle/input/pretrained-bird-vocalization-cnn/milsed_7block_dense-birdsongs_2_1618704934_e5b73727.h5')\n",
    "model.load_weights('input/pretrained-bird-vocalization-cnn/milsed_7block_dense-birdsongs_2_1618704934_e5b73727.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<kapre.time_frequency.STFT at 0x159ee1430>,\n",
       " <kapre.time_frequency.Magnitude at 0x159ee1730>,\n",
       " <kapre.time_frequency.ApplyFilterbank at 0x159ee17f0>,\n",
       " <kapre.time_frequency.MagnitudeToDecibel at 0x159ee1ac0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a170640>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a1bc610>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a0e4b20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a11e5e0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a16c8b0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x15a1b2790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a16c1c0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a1b2070>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a156760>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a1b2b80>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x15a144880>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a171370>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a12e8b0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a162af0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a144fa0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x15a17a9d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a188fa0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a12e580>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a181a30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a22cee0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x15a2254c0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a1854f0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a1905e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a0f0460>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a15e2b0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x15a1a4b50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a1a7d30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a15bcd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a1a7550>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a15b130>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x159f75850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a2116d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a180850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x15a19a460>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x15a137700>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x15a22cd90>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalMaxPooling2D at 0x15a22c070>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15a1828e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15a1801c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x159ec9700>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect layers\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all but the last 3 layers\n",
    "for layerid in range(len(model.layers) - 3):\n",
    "    model.layers[layerid].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False stft\n",
      "False magnitude\n",
      "False apply_filterbank\n",
      "False magnitude_to_decibel\n",
      "False batch_normalization\n",
      "False conv2d\n",
      "False batch_normalization_1\n",
      "False conv2d_1\n",
      "False batch_normalization_2\n",
      "False max_pooling2d\n",
      "False conv2d_2\n",
      "False batch_normalization_3\n",
      "False conv2d_3\n",
      "False batch_normalization_4\n",
      "False max_pooling2d_1\n",
      "False conv2d_4\n",
      "False batch_normalization_5\n",
      "False conv2d_5\n",
      "False batch_normalization_6\n",
      "False max_pooling2d_2\n",
      "False conv2d_6\n",
      "False batch_normalization_7\n",
      "False conv2d_7\n",
      "False batch_normalization_8\n",
      "False max_pooling2d_3\n",
      "False conv2d_8\n",
      "False batch_normalization_9\n",
      "False conv2d_9\n",
      "False batch_normalization_10\n",
      "False max_pooling2d_4\n",
      "False conv2d_10\n",
      "False batch_normalization_11\n",
      "False conv2d_11\n",
      "False batch_normalization_12\n",
      "False max_pooling2d_5\n",
      "False conv2d_12\n",
      "False batch_normalization_13\n",
      "False conv2d_13\n",
      "False batch_normalization_14\n",
      "False max_pooling2d_6\n",
      "False global_max_pooling2d\n",
      "True dense\n",
      "True dense_1\n",
      "True dense_2\n"
     ]
    }
   ],
   "source": [
    "# make sure correct layers are frozen.\n",
    "for layer in model.layers:\n",
    "    print(layer.trainable, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to create an input generator for the current dataset.  The datagenerator for the project from which this model came is very inefficient so I will use the example generator provided by kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "\n",
    "#count = 0\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        count += 1\n",
    "#print('counted %d files.' % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_audio_dir = 'input/birdclef-2021/train_short_audio'\n",
    "train_file_pattern = os.path.join(short_audio_dir, '*/*.ogg')\n",
    "audio_files = glob(train_file_pattern)\n",
    "DATASET_SIZE = len(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=K.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[K.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple pipeline.\n",
    "\n",
    "- Split in train test by class.\n",
    "- Load files in dataset.\n",
    "- Pass to model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Val split\n",
    "def split_from_df(df, class_col, val_prop, test_prop=0):\n",
    "\n",
    "    train = {'files': [], 'labels':[]}\n",
    "    val = {'files': [], 'labels':[]}\n",
    "    test = {'files': [], 'labels':[]}\n",
    "    \n",
    "    grouped = df.groupby(class_col)\n",
    "    for name, group in grouped:\n",
    "        \n",
    "        # randomly select test rows\n",
    "        test_rows = group.sample(frac=test_prop, replace=False)\n",
    "        test['files'] += test_rows['files'].tolist()\n",
    "        test['labels'] += [name] * len(test_rows)\n",
    "        \n",
    "        # remove the test rows\n",
    "        group = group.drop(test_rows.index)\n",
    "        \n",
    "        #randomly select validation rows\n",
    "        val_rows = group.sample(frac=val_prop, replace=False)\n",
    "        val['files'] += val_rows['files'].tolist()\n",
    "        val['labels'] += [name] * len(val_rows)\n",
    "        \n",
    "        # remove the validation rows\n",
    "        group = group.drop(val_rows.index)\n",
    "        \n",
    "        # train is everything left over\n",
    "        train_rows = group\n",
    "        train['files'] += train_rows['files'].tolist()\n",
    "        train['labels'] += [name] * len(train_rows)\n",
    "        \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "files = glob('input/birdclef-2021/train_short_audio/*/*.ogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/birdclef-2021/train_short_audio/acafly/XC109605.ogg',\n",
       " 'input/birdclef-2021/train_short_audio/acafly/XC11209.ogg',\n",
       " 'input/birdclef-2021/train_short_audio/acafly/XC127032.ogg',\n",
       " 'input/birdclef-2021/train_short_audio/acafly/XC129974.ogg',\n",
       " 'input/birdclef-2021/train_short_audio/acafly/XC129981.ogg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acafly', 'acafly', 'acafly', 'acafly', 'acafly']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [f.split('/')[-2] for f in files]\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/acafly/X...</td>\n",
       "      <td>acafly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/acafly/X...</td>\n",
       "      <td>acafly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/acafly/X...</td>\n",
       "      <td>acafly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/acafly/X...</td>\n",
       "      <td>acafly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/acafly/X...</td>\n",
       "      <td>acafly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62869</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/yetvir/X...</td>\n",
       "      <td>yetvir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62870</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/yetvir/X...</td>\n",
       "      <td>yetvir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62871</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/yetvir/X...</td>\n",
       "      <td>yetvir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62872</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/yetvir/X...</td>\n",
       "      <td>yetvir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62873</th>\n",
       "      <td>input/birdclef-2021/train_short_audio/yetvir/X...</td>\n",
       "      <td>yetvir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62874 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   files  labels\n",
       "0      input/birdclef-2021/train_short_audio/acafly/X...  acafly\n",
       "1      input/birdclef-2021/train_short_audio/acafly/X...  acafly\n",
       "2      input/birdclef-2021/train_short_audio/acafly/X...  acafly\n",
       "3      input/birdclef-2021/train_short_audio/acafly/X...  acafly\n",
       "4      input/birdclef-2021/train_short_audio/acafly/X...  acafly\n",
       "...                                                  ...     ...\n",
       "62869  input/birdclef-2021/train_short_audio/yetvir/X...  yetvir\n",
       "62870  input/birdclef-2021/train_short_audio/yetvir/X...  yetvir\n",
       "62871  input/birdclef-2021/train_short_audio/yetvir/X...  yetvir\n",
       "62872  input/birdclef-2021/train_short_audio/yetvir/X...  yetvir\n",
       "62873  input/birdclef-2021/train_short_audio/yetvir/X...  yetvir\n",
       "\n",
       "[62874 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df = pd.DataFrame({'files':files,'labels':labels})\n",
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_from_df(files_df, 'labels', 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53442, 9432, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['labels']), len(val['labels']), len(test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def get_labels_from_path(filename):\n",
    "    label = tf.strings.split(filename, sep='/')[-2]\n",
    "    return filename, label\n",
    "    \n",
    "def get_file_dataset(file_paths):\n",
    "#     file_paths = 'input/birdclef-2021/train_short_audio/*/*.ogg'\n",
    "    file_paths_ds = tf.data.Dataset.list_files(file_paths, shuffle=False)\n",
    "    ds = file_paths_ds.map(get_labels_from_path, num_parallel_calls=3) #AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# def load_audio(file_path, label):\n",
    "#     audio = tfio.audio.AudioIOTensor(file_path, dtype=tf.int32)\n",
    "#     return audio[0], label\n",
    "\n",
    "def load_audio(filename, label):\n",
    "    def _soundfile_read(filename):\n",
    "        with open(filename.numpy(), 'br') as audio_file:\n",
    "            tmp = io.BytesIO(audio_file.read())\n",
    "            audio, rate = sf.read(tmp, dtype='float32')\n",
    "        return audio\n",
    "    [audio,] = tf.py_function(_soundfile_read, [filename], [tf.float32]))\n",
    "    return audio, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, shuffle_buffer_size=128, batch_size=32):\n",
    "    # Randomly shuffle\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    \n",
    "    # load and decode audio from file paths\n",
    "    ds = ds.map(load_audio, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # repeat dataset forever\n",
    "    ds = ds.repeat()\n",
    "    \n",
    "    # Prepare batches\n",
    "    ds.batch(batch_size)\n",
    "    \n",
    "    # Prefetch\n",
    "    ds = ds.prefetch(buffer_size=128) # AUTOTUNE\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = get_file_dataset(train['files'])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), ()), types: (tf.int32, tf.string)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = prepare_for_training(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_iter = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(ds_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in ds:\n",
    "#     row[0]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audio-ml]",
   "language": "python",
   "name": "conda-env-audio-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
